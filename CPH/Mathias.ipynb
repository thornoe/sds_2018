{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of distance to school, metro and jail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code is structured as followed\n",
    "- Calculating distances to a top 20% school\n",
    "    - Scraping list of best all schools \n",
    "    - Use *`geocode`* to get coordinates\n",
    "    - Calculate distances from each apartment\n",
    "    - Construct list of minimum distance to top school\n",
    "- Calculating distances to a metro\n",
    "- Calculating distances to a jail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School data\n",
    "In the first part of this code, we retrieve data on municipalities and which zip code that belong to which municipality.\n",
    "\n",
    "Because many of the columns are intertwined, we need to split and merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ngottschalck/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Get zip codes and municipalities from DST\n",
    "url_post = 'https://www.dst.dk/ext/4393839853/0/kundecenter/Tabel-Postnumre-kommuner-og-regioner--xlsx'\n",
    "df_muni = pd.read_excel(url_post)\n",
    "df2_muni = df_muni[4:]\n",
    "df2_muni.columns = ['Zip', 'Municipality','Region']\n",
    "\n",
    "\n",
    "# Split data: we want to seperate zip code and village as well as municipality number and municipality\n",
    "zip_split = pd.DataFrame(df2_muni.Zip.str.split(' ',1).tolist(),\n",
    "                                   columns = ['Zip','Village'])\n",
    "\n",
    "mun_split = pd.DataFrame(df2_muni.Municipality.str.split(' ',1).tolist(),\n",
    "                                   columns = ['Mun. no.','Municipality'])\n",
    "\n",
    "# Merge data back together\n",
    "merge = pd.concat([zip_split, mun_split], axis=1, sort=False)\n",
    "mun_zip = merge[['Zip','Municipality']] \n",
    "\n",
    "# Construct new variable that only contain municpalities with zip code below 3000\n",
    "mun_zip['Int zip'] = mun_zip['Zip'].astype(int)\n",
    "our_sample = mun_zip[(mun_zip['Int zip'] < 3000)]\n",
    "\n",
    "# Drop duplicates so we have a simple list of the municipalities we are interested in\n",
    "municipalities = our_sample['Municipality'].drop_duplicates().reset_index()\n",
    "\n",
    "# List of our chosen municipalities\n",
    "municip = pd.DataFrame(municipalities['Municipality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table of school ranking\n",
    "url_school = 'https://www.sondagsavisen.dk/familien/2015-08-22-se-hele-listen-her-er-danmarks-bedste-og-vaerste-skole/'\n",
    "html = pd.read_html(url_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school = pd.DataFrame(html[0])\n",
    "head_school = df_school.rename(columns = df_school.iloc[0])\n",
    "school = head_school[1:]\n",
    "\n",
    "# Only include schools within our chosen municipalities\n",
    "schools = school[school['Kommune'].isin(municip['Municipality'])]\n",
    "n_school = schools.groupby(['Kommune']).size().reset_index(name='Count')\n",
    "\n",
    "\n",
    "# Find threshold for best schools. The numer of schools are chosen such that \n",
    "# we divide number of schools in a municipality with five to get the relative best schools\n",
    "thresh = [n_school['Kommune'], round(n_school['Count']//5)]\n",
    "threshold = pd.DataFrame(thresh).transpose()\n",
    "\n",
    "for i in range(0,len(threshold)):\n",
    "    if threshold['Count'][i]==0:\n",
    "        threshold['Count'][i]=1\n",
    "threshold\n",
    "\n",
    "# Merge threshold to our schools, so we can exclude schools with ranking above threshold\n",
    "schools_merge = pd.merge(schools, threshold, how='left',\n",
    "        left_on='Kommune', right_on='Kommune')\n",
    "\n",
    "schools_merge['Ranking'] = schools_merge['Placering Kommune'].astype(int)\n",
    "\n",
    "school_drop = schools_merge[(schools_merge.Ranking <= schools_merge.Count)].reset_index(drop = True)\n",
    "school_drop\n",
    "school_final = school_drop.drop(['Placering Kommune', 'UE 2014', 'Placering landsplan','Privat/ Offentlig','Count'], axis =1)\n",
    "\n",
    "# Rename schools that cannot be found using geocode\n",
    "new_name = []\n",
    "for i, row in school_final['Skolenavn'].iteritems():\n",
    "    if 'Østerhøjskolen' in row:\n",
    "        new_name.append('Østerhøj skole')\n",
    "    elif 'Kaptajn Johnsens Skole' in row:\n",
    "        new_name.append('Lykkesholms Alle 3A')\n",
    "    elif 'Sct. Joseph Søstrenes Skole S/I' in row:\n",
    "        new_name.append('Skovkrogen 19')\n",
    "    elif 'Atheneskolen – skolen for børn med særlige forudsætninger' in row:\n",
    "        new_name.append('Rosenkæret 22A')\n",
    "    elif 'Bagsværd Gymnasiums Grundskole' in row:\n",
    "        new_name.append('Aldershvilevej 138')\n",
    "    elif 'Greve Privatskole' in row:\n",
    "        new_name.append('Hundige Bygade 2')\n",
    "    elif 'Tjørnelyskolen' in row:\n",
    "        new_name.append('Lillevangsvej 48')\n",
    "    elif 'Skt. Pauls Skole' in row:\n",
    "        new_name.append('Sankt Pauls Skole')\n",
    "    elif 'Ådalens Privatskole' in row:\n",
    "        new_name.append('Skovvej 15')\n",
    "    elif 'Rungsted Private Realskole' in row:\n",
    "        new_name.append('Vallerød Banevej 23')\n",
    "    elif 'Hay Skolen' in row:\n",
    "        new_name.append('Sankt Hans Gade 25')\n",
    "    elif 'Amager’s International School' in row:\n",
    "        new_name.append('Engvej 141, 2300 København')\n",
    "    elif 'Jinnah International School' in row:\n",
    "        new_name.append('Skjulhøj Alle 59')\n",
    "    elif 'Iqra Privatskole' in row:\n",
    "        new_name.append('Hermodsgade 28')\n",
    "    elif 'Copenhagen Euro School' in row:\n",
    "        new_name.append('Gammel Kongevej 15')\n",
    "    elif 'Nørre Fælled Skole' in row:\n",
    "        new_name.append('Biskop Krags Vænge 7')\n",
    "    elif 'Al Hikma Skolen' in row:\n",
    "        new_name.append('Ellebjergvej 50')\n",
    "    elif 'Øresunds Internationale Skole' in row:\n",
    "        new_name.append('Engvej 153, 2300 København')\n",
    "    elif 'Sjællands Privatskole' in row:\n",
    "        new_name.append('Nattergalevej 32')\n",
    "    elif 'Baunehøjskolen' in row:\n",
    "        new_name.append('Baunegårdsvej')\n",
    "    elif 'Dronninggårdskolen' in row:\n",
    "        new_name.append('Rønnebærvej 33')\n",
    "    elif 'Uglegårdsskolen – Uglegård afdeling' in row:\n",
    "        new_name.append('Tingsryds Alle 25')\n",
    "    else:\n",
    "        new_name.append(row.split(',', 1)[0]) # split once, keep 1st part\n",
    "\n",
    "school_final.insert(loc=0, column='School name', value=new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip3: command not found\n",
      "/bin/sh: pip3: command not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/57 [00:00<00:17,  3.19it/s]\u001b[A\n",
      "  4%|▎         | 2/57 [00:00<00:12,  4.56it/s]\u001b[A\n",
      "  5%|▌         | 3/57 [00:00<00:10,  5.26it/s]\u001b[A\n",
      "  7%|▋         | 4/57 [00:00<00:09,  5.67it/s]\u001b[A\n",
      "  9%|▉         | 5/57 [00:00<00:08,  6.02it/s]\u001b[A\n",
      " 11%|█         | 6/57 [00:00<00:08,  6.28it/s]\u001b[A\n",
      " 12%|█▏        | 7/57 [00:01<00:07,  6.48it/s]\u001b[A\n",
      " 14%|█▍        | 8/57 [00:01<00:07,  6.60it/s]\u001b[A\n",
      " 16%|█▌        | 9/57 [00:01<00:07,  6.76it/s]\u001b[A\n",
      " 18%|█▊        | 10/57 [00:01<00:06,  6.88it/s]\u001b[A\n",
      " 19%|█▉        | 11/57 [00:01<00:06,  6.97it/s]\u001b[A\n",
      " 21%|██        | 12/57 [00:01<00:06,  7.05it/s]\u001b[A\n",
      " 23%|██▎       | 13/57 [00:01<00:06,  7.07it/s]\u001b[A\n",
      " 25%|██▍       | 14/57 [00:01<00:06,  7.13it/s]\u001b[A\n",
      " 26%|██▋       | 15/57 [00:02<00:05,  7.15it/s]\u001b[A\n",
      " 28%|██▊       | 16/57 [00:02<00:05,  7.20it/s]\u001b[A\n",
      " 30%|██▉       | 17/57 [00:02<00:05,  7.25it/s]\u001b[A\n",
      " 32%|███▏      | 18/57 [00:02<00:05,  7.26it/s]\u001b[A\n",
      " 33%|███▎      | 19/57 [00:02<00:05,  7.29it/s]\u001b[A\n",
      " 35%|███▌      | 20/57 [00:02<00:05,  7.31it/s]\u001b[A\n",
      " 37%|███▋      | 21/57 [00:02<00:04,  7.34it/s]\u001b[A\n",
      " 39%|███▊      | 22/57 [00:02<00:04,  7.36it/s]\u001b[A\n",
      " 40%|████      | 23/57 [00:03<00:04,  7.40it/s]\u001b[A\n",
      " 42%|████▏     | 24/57 [00:03<00:04,  7.40it/s]\u001b[A\n",
      " 44%|████▍     | 25/57 [00:03<00:04,  7.39it/s]\u001b[A\n",
      " 46%|████▌     | 26/57 [00:03<00:04,  7.34it/s]\u001b[A\n",
      " 47%|████▋     | 27/57 [00:03<00:04,  7.33it/s]\u001b[A\n",
      " 49%|████▉     | 28/57 [00:03<00:03,  7.34it/s]\u001b[A\n",
      " 51%|█████     | 29/57 [00:03<00:03,  7.38it/s]\u001b[A\n",
      " 53%|█████▎    | 30/57 [00:04<00:03,  7.30it/s]\u001b[A\n",
      " 54%|█████▍    | 31/57 [00:04<00:03,  7.32it/s]\u001b[A\n",
      " 56%|█████▌    | 32/57 [00:04<00:03,  7.34it/s]\u001b[A\n",
      " 58%|█████▊    | 33/57 [00:04<00:03,  7.33it/s]\u001b[A\n",
      " 60%|█████▉    | 34/57 [00:04<00:03,  7.34it/s]\u001b[A\n",
      " 61%|██████▏   | 35/57 [00:04<00:02,  7.36it/s]\u001b[A\n",
      " 63%|██████▎   | 36/57 [00:04<00:02,  7.36it/s]\u001b[A\n",
      " 65%|██████▍   | 37/57 [00:05<00:02,  7.39it/s]\u001b[A\n",
      " 67%|██████▋   | 38/57 [00:05<00:02,  7.40it/s]\u001b[A\n",
      " 68%|██████▊   | 39/57 [00:05<00:02,  7.39it/s]\u001b[A\n",
      " 70%|███████   | 40/57 [00:05<00:02,  7.38it/s]\u001b[A\n",
      " 72%|███████▏  | 41/57 [00:05<00:02,  7.40it/s]\u001b[A\n",
      " 74%|███████▎  | 42/57 [00:05<00:02,  7.42it/s]\u001b[A\n",
      " 75%|███████▌  | 43/57 [00:05<00:01,  7.43it/s]\u001b[A\n",
      " 77%|███████▋  | 44/57 [00:05<00:01,  7.43it/s]\u001b[A\n",
      " 79%|███████▉  | 45/57 [00:06<00:01,  7.43it/s]\u001b[A\n",
      " 81%|████████  | 46/57 [00:06<00:01,  7.44it/s]\u001b[A\n",
      " 82%|████████▏ | 47/57 [00:06<00:01,  7.44it/s]\u001b[A\n",
      " 84%|████████▍ | 48/57 [00:06<00:01,  7.46it/s]\u001b[A\n",
      " 86%|████████▌ | 49/57 [00:06<00:01,  7.42it/s]\u001b[A\n",
      " 88%|████████▊ | 50/57 [00:06<00:00,  7.42it/s]\u001b[A\n",
      " 89%|████████▉ | 51/57 [00:06<00:00,  7.44it/s]\u001b[A\n",
      " 91%|█████████ | 52/57 [00:06<00:00,  7.44it/s]\u001b[A\n",
      " 93%|█████████▎| 53/57 [00:07<00:00,  7.45it/s]\u001b[A\n",
      " 95%|█████████▍| 54/57 [00:07<00:00,  7.45it/s]\u001b[A\n",
      " 96%|█████████▋| 55/57 [00:07<00:00,  7.45it/s]\u001b[A\n",
      " 98%|█████████▊| 56/57 [00:07<00:00,  7.46it/s]\u001b[A\n",
      "100%|██████████| 57/57 [00:07<00:00,  7.46it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# [Getting latitude and longitude for schools]\n",
    "# Import packages\n",
    "!pip3 install tqdm\n",
    "!pip3 install geopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, tqdm\n",
    "import geopy.geocoders  # GeoPy - see https://pypi.org/project/geopy/\n",
    "from geopy.geocoders import Nominatim # retrieve coordinates from addresses etc.\n",
    "geopy.geocoders.options.default_user_agent = 'my_app/1'\n",
    "geopy.geocoders.options.default_timeout = 15\n",
    "\n",
    "geolocator = Nominatim()\n",
    "# geolocator.headers  # check header\n",
    "# geolocator.timeout  # check time_out\n",
    "latitude = []\n",
    "longitude = []\n",
    "address = []\n",
    "\n",
    "for row in tqdm.tqdm(school_final['School name']):\n",
    "    row_string = str(row)\n",
    "    location = geolocator.geocode(row_string)\n",
    "    if isinstance(location, geopy.location.Location):\n",
    "        latitude.append(float(location.latitude))\n",
    "        longitude.append(float(location.longitude))\n",
    "    else:\n",
    "        print('Not found: ',row_string)\n",
    "        latitude.append(None)\n",
    "        longitude.append(None)\n",
    "school_final.insert(loc=0, column='Latitude', value=latitude)\n",
    "school_final.insert(loc=0, column='Longitude', value=longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distances to school from apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# School coordinates\n",
    "school_coord = pd.DataFrame([school_final['Longitude'], school_final['Latitude']]).transpose()\n",
    "\n",
    "##############\n",
    "# FINAL DATASET FOR APARTMENTS\n",
    "################\n",
    "\n",
    "# Apartment coordinates\n",
    "data_apart = pd.read_csv('/Users/Ngottschalck/Desktop/Mathias/Python/priser.csv')\n",
    "apartment_coord = pd.DataFrame([data_apart['Longitude'], data_apart['Latitude']]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance between each school and apartment\n",
    "from geopy.distance import geodesic as dist\n",
    "\n",
    "school_distance = []\n",
    "for i in range(0,len(apartment_coord)):\n",
    "    for p in range(0,len(school_coord)):\n",
    "        apart_dist = (apartment_coord['Latitude'][i],apartment_coord['Longitude'][i])\n",
    "        school_dist = (school_coord['Latitude'][p],school_coord['Longitude'][p])\n",
    "        all_dist = dist(apart_dist,school_dist).km\n",
    "        school_distance.append(all_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct a function to split data so we have list divided over each apartment with distance to each school\n",
    "# i.e. split_dist[i] corresponds to apartment i \n",
    "\n",
    "def splitDataFrameIntoSmaller(df, chunkSize = 10000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf\n",
    "\n",
    "split_dist = splitDataFrameIntoSmaller(school_distance,len(school_coord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_school = []\n",
    "for i in range(0,len(split_dist)-1):\n",
    "    minimum = min(split_dist[i])\n",
    "    min_dist_school.append(minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jail data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get jail data from github \n",
    "jail_data = pd.read_csv('https://raw.githubusercontent.com/thornoe/sds_2018/master/CPH/Data/jail.csv', sep = ';')/1000000\n",
    "\n",
    "# Calculate distance from jail to each apartment\n",
    "jail_distance = []\n",
    "for i in range(0,len(apartment_coord)):\n",
    "    for p in range(0,len(jail_data)):\n",
    "        apart_dist = (apartment_coord['Latitude'][i],apartment_coord['Longitude'][i])\n",
    "        jail_dist = (jail_data['Lat'][p],jail_data['Long'][p])\n",
    "        all_dist = dist(apart_dist,jail_dist).km\n",
    "        jail_distance.append(all_dist)\n",
    "\n",
    "# Split data\n",
    "split_jail = splitDataFrameIntoSmaller(jail_distance,len(jail_data)) \n",
    "\n",
    "# Calculate minimum distance to jail\n",
    "min_dist_jail = []\n",
    "for i in range(0,len(split_jail)-1):\n",
    "    minimum = min(split_jail[i])\n",
    "    min_dist_jail.append(minimum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get church data from github \n",
    "metro_data = pd.read_csv('https://raw.githubusercontent.com/thornoe/sds_2018/master/CPH/Data/metro.csv', sep = ';')/1000000\n",
    "\n",
    "# Calculate distance from jail to each apartment\n",
    "metro_distance = []\n",
    "for i in range(0,len(apartment_coord)):\n",
    "    for p in range(0,len(metro_data)):\n",
    "        apart_dist = (apartment_coord['Latitude'][i],apartment_coord['Longitude'][i])\n",
    "        metro_dist = (metro_data['lat'][p],metro_data['long'][p])\n",
    "        all_dist = dist(apart_dist,metro_dist).km\n",
    "        metro_distance.append(all_dist)\n",
    "\n",
    "# Split data\n",
    "split_metro = splitDataFrameIntoSmaller(metro_distance,len(metro_data)) \n",
    "\n",
    "# Calculate minimum distance to jail\n",
    "min_dist_metro = []\n",
    "for i in range(0,len(split_metro)-1):\n",
    "    minimum = min(split_metro[i])\n",
    "    min_dist_metro.append(minimum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
