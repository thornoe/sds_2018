{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load packages for Machine Learning\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set and create subset to perform Machine Learning on\n",
    "data_apart = pd.read_csv('https://raw.githubusercontent.com/thornoe/sds_2018/master/CPH/Data/final_data.csv', index_col=0)\n",
    "ML_set = data_apart[['log_sqm_price', 'Municipality', 'Floor', 'Land_area','Rooms', 'Area', 'Owner_expense', 'Energy_saving', \n",
    "                     'School_dist', 'Metro_dist', 'Jail_dist', 'Centrum_coor']]\n",
    "ML_dummy = pd.get_dummies(ML_set, columns=['Municipality'])\n",
    "\n",
    "X = ML_dummy.iloc[:,1:]\n",
    "y = ML_set[['log_sqm_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into development (2/3) and test data (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "# splitting development into train (1/3) and validation (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 First set polynomial features = 3 and create pipelines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#        LINEAR           #\n",
    "###########################\n",
    "pipe_lr = make_pipeline(PolynomialFeatures(degree = 3,include_bias=False), \n",
    "                            StandardScaler(),\n",
    "                            LinearRegression())\n",
    "\n",
    "###########################\n",
    "#        Lasso            #\n",
    "########################### \n",
    "pipe_lasso = make_pipeline(PolynomialFeatures(degree=3, include_bias=False), \n",
    "                                  StandardScaler(),\n",
    "                                  Lasso())\n",
    "\n",
    "###########################\n",
    "#        LASSO CV         #\n",
    "###########################\n",
    "lambdas = np.logspace(-4,4, 12)\n",
    "kfolds = KFold(n_splits=10)\n",
    "RMSE_lassoCV = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=3,include_bias=False), \n",
    "                                  StandardScaler(),\n",
    "                                  Lasso(alpha=lambda_, random_state=1))    \n",
    "    RMSE_lassoCV_ = []\n",
    "    \n",
    "    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n",
    "        \n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "\n",
    "        pipe_lassoCV.fit(X_train, y_train)\n",
    "        RMSE_lassoCV_.append(mse(y_val, pipe_lassoCV.predict(X_val))**(1/2))    \n",
    "    RMSE_lassoCV.append(RMSE_lassoCV_)\n",
    "\n",
    "optimalCV = pd.DataFrame(RMSE_lassoCV, index=lambdas).mean(axis=1).nsmallest(1)\n",
    "print(optimalCV) # This prints optimal lambda and RMSE. \n",
    "\n",
    "# Fit training data with optimal lambda\n",
    "pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=3, include_bias=False), \n",
    "                                StandardScaler(),\n",
    "                                Lasso(alpha=optimalCV.index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Fit on development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(X_dev, y_dev)\n",
    "pipe_lasso.fit(X_dev,y_dev)\n",
    "pipe_lassoCV.fit(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Get MAE and RMSE from test data and make table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model\n",
    "MAE_lr = mae(y_test, pipe_lr.predict(X_test))\n",
    "RMSE_lr = mse(y_test, pipe_lr.predict(X_test))**(1/2)\n",
    "\n",
    "# Lasso model\n",
    "MAE_lasso = mae(y_test, pipe_lasso.predict(X_test))\n",
    "RMSE_lasso = mse(y_test, pipe_lasso.predict(X_test))**(1/2)\n",
    "\n",
    "# Lasso CV\n",
    "MAE_lasso_CV = mae(y_test, pipe_lassoCV.predict(X_test))\n",
    "RMSE_lasso_CV = mse(y_test, pipe_lassoCV.predict(X_test))**(1/2)\n",
    "\n",
    "# Generate table of results\n",
    "MAE = [MAE_lr, MAE_lasso, MAE_lasso_CV]\n",
    "RMSE = [RMSE_lr, RMSE_lasso, RMSE_lasso_CV]\n",
    "\n",
    "Results = pd.DataFrame({'MAE': MAE, 'RMSE': RMSE}, index=('Linear', 'Lasso', 'Lasso CV'))\n",
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Optimize on polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Create pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear optimal: 1\n",
      "Lasso optimal: 1\n",
      "0.0001    0.176556\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "#        LINEAR           #\n",
    "###########################\n",
    "pol = range(1,6)\n",
    "perform_lr = []\n",
    "\n",
    "# First loop over polynomial degrees to find best performance for linear\n",
    "for dg in pol:\n",
    "    pipe_lr = make_pipeline(PolynomialFeatures(degree = dg,include_bias=False), \n",
    "                           StandardScaler(),\n",
    "                           LinearRegression())  \n",
    "    # Fit the training data\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "    perform_lr.append(mse(y_val, pipe_lr.predict(X_val))**(1/2))\n",
    "\n",
    "optimal_pol_lr = pd.Series(perform_lr,index=pol).nsmallest(1)\n",
    "# Define pipeline for linear\n",
    "pipe_lr = make_pipeline(PolynomialFeatures(degree = optimal_pol_lr.index[0],include_bias=False), \n",
    "                           StandardScaler(),\n",
    "                           LinearRegression())\n",
    "print('Linear optimal:', optimal_pol_lr.index[0])\n",
    "###########################\n",
    "#        Lasso            #\n",
    "###########################\n",
    "\n",
    "perform_lasso = []\n",
    "\n",
    "# First loop over polynomial degrees to find best performance\n",
    "for dg in pol:\n",
    "    pipe_lasso = make_pipeline(PolynomialFeatures(degree = dg,include_bias=False), \n",
    "                               StandardScaler(),\n",
    "                               Lasso()) \n",
    "    # Fit the training data\n",
    "    pipe_lasso.fit(X_train, y_train)\n",
    "    perform_lasso.append(mse(y_val, pipe_lasso.predict(X_val))**(1/2))\n",
    "optimal_pol_lasso = pd.Series(perform_lasso,index=pol).nsmallest(1)\n",
    "# Define pipeline for lasso\n",
    "pipe_lasso = make_pipeline(PolynomialFeatures(degree=optimal_pol_lasso.index[0], include_bias=False), \n",
    "                              StandardScaler(),\n",
    "                              Lasso())\n",
    "\n",
    "print('Lasso optimal:', optimal_pol_lasso.index[0])\n",
    "###########################\n",
    "#        LASSO CV         #\n",
    "###########################\n",
    "\n",
    "lambdas = np.logspace(-4,4, 12)\n",
    "kfolds = KFold(n_splits=10)\n",
    "RMSE_lassoCV = []\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=optimal_pol_lasso.index[0],include_bias=False), \n",
    "                                  StandardScaler(),\n",
    "                                  Lasso(alpha=lambda_, random_state=1))    \n",
    "    RMSE_lassoCV_ = []\n",
    "    \n",
    "    for train_idx, val_idx in kfolds.split(X_dev, y_dev):\n",
    "        \n",
    "        X_train, y_train, = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx] \n",
    "\n",
    "        pipe_lassoCV.fit(X_train, y_train)\n",
    "        RMSE_lassoCV_.append(mse(y_val, pipe_lassoCV.predict(X_val))**(1/2))    \n",
    "    RMSE_lassoCV.append(RMSE_lassoCV_)\n",
    "\n",
    "optimalCV = pd.DataFrame(RMSE_lassoCV, index=lambdas).mean(axis=1).nsmallest(1)\n",
    "print(optimalCV) # This prints optimal lambda and RMSE. \n",
    "\n",
    "# Lasso CV pipeline\n",
    "pipe_lassoCV = make_pipeline(PolynomialFeatures(degree=optimal_pol_lasso.index[0], include_bias=False), \n",
    "                                StandardScaler(),\n",
    "                                Lasso(alpha=optimalCV.index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Fit on development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=1, include_bias=False, interaction_only=False)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(X_dev, y_dev)\n",
    "pipe_lasso.fit(X_dev,y_dev)\n",
    "pipe_lassoCV.fit(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Get MAE and RMSE from test data and make table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE      RMSE\n",
      "Linear    0.133714  0.179479\n",
      "Lasso     0.221933  0.281679\n",
      "Lasso CV  0.133730  0.179454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrr}\\n\\\\toprule\\n{} &       MAE &      RMSE \\\\\\\\\\n\\\\midrule\\nLinear   &  0.133714 &  0.179479 \\\\\\\\\\nLasso    &  0.221933 &  0.281679 \\\\\\\\\\nLasso CV &  0.133730 &  0.179454 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear model\n",
    "MAE_lr = mae(y_test, pipe_lr.predict(X_test))\n",
    "RMSE_lr = mse(y_test, pipe_lr.predict(X_test))**(1/2)\n",
    "\n",
    "# Lasso model\n",
    "MAE_lasso = mae(y_test, pipe_lasso.predict(X_test))\n",
    "RMSE_lasso = mse(y_test, pipe_lasso.predict(X_test))**(1/2)\n",
    "\n",
    "# Lasso CV\n",
    "MAE_lasso_CV = mae(y_test, pipe_lassoCV.predict(X_test))\n",
    "RMSE_lasso_CV = mse(y_test, pipe_lassoCV.predict(X_test))**(1/2)\n",
    "\n",
    "# Generate table of results\n",
    "MAE = [MAE_lr, MAE_lasso, MAE_lasso_CV]\n",
    "RMSE = [RMSE_lr, RMSE_lasso, RMSE_lasso_CV]\n",
    "\n",
    "Results2 = pd.DataFrame({'MAE': MAE, 'RMSE': RMSE}, index=('Linear', 'Lasso', 'Lasso CV'))\n",
    "print(Results2)\n",
    "Results2.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
